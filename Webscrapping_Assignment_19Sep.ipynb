{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1b6174b1-4737-4786-87ab-d16aa9d53f72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter the product to search:  television\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                         Product Name   Price Rating\n",
      "0   Xiaomi 125 cm (50 inches) X Series 4K LED Smar...  33,999      -\n",
      "1   Xiaomi 138 cm (55 inches) X Pro QLED Series Sm...  49,999      -\n",
      "2   Redmi 80 cm (32 inches) F Series HD Ready Smar...  10,999      -\n",
      "3   VW 80 cm (32 inches) Frameless Series HD Ready...   7,499      -\n",
      "4   Kodak 80 cm (32 inches) Special Edition Series...   7,999      -\n",
      "5   Redmi Xiaomi 108 cm (43 inches) 4K Ultra HD Sm...  19,990      -\n",
      "6   TCL 101 cm (40 inches) Mettalic Bezel-Less Ful...       -      -\n",
      "7   Samsung 80 cm (32 inches) HD Ready Smart LED T...  15,240      -\n",
      "8   TCL 80.04 cm (32 inches) Metallic Bezel-Less H...  10,990      -\n",
      "9   Xiaomi Smart TV A 80 cm (32) HD Ready Smart Go...  14,489      -\n",
      "10  Acer 80 cm (32 inches) V Series HD Ready Smart...  13,999      -\n",
      "11  Wobble 139.7 cm (55 inches) UD Series 4K Ultra...  30,999      -\n",
      "12  LG 80 cm (32 inches) HD Ready Smart LED TV 32L...  14,490      -\n",
      "13  LG 80 cm (32 inches) HD Ready Smart LED TV 32L...  15,990      -\n",
      "14  VW 80 cm (32 inches) Playwall Frameless Series...   7,999      -\n",
      "15  LG 80 cm (32 inches) HD Ready Smart LED TV 32L...  14,490      -\n",
      "16  TCL 80.04 cm (32 inches) Metallic Bezel-Less S...  13,990      -\n",
      "17  VW 109 cm (43 inches) Linux Series Frameless F...  14,499      -\n",
      "18  Samsung 108 cm (43 inches) Crystal 4K Neo Seri...       -      -\n",
      "19  Samsung 108 cm (43 inches) Full HD Smart LED T...  26,990      -\n",
      "20  LG 139 cm (55 inches) 4K Ultra HD Smart LED TV...  43,990      -\n",
      "21  MI 108 cm (43 inches) A Series Full HD Smart G...  21,999      -\n"
     ]
    }
   ],
   "source": [
    "''''Qn1\n",
    "\n",
    "Write a python program which searches all the product under a particular product from www.amazon.in. The \n",
    "product to be searched will be taken as input from user. For e.g. If user input is ‘guitar’. Then search for \n",
    "guitars'''\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "path_chromedriver = r'C:\\chromedriver-win64\\chromedriver.exe'  # path to chromedriver executable\n",
    "service = Service(path_chromedriver)\n",
    "driver = webdriver.Chrome(service=service)\n",
    "\n",
    "# user input for product to search\n",
    "product_name = input(\"Enter the product to search: \")\n",
    "\n",
    "# Open Amazon\n",
    "driver.get('https://www.amazon.in')\n",
    "\n",
    "\n",
    "time.sleep(3)\n",
    "\n",
    "# search bar and enter the product name\n",
    "search_box = driver.find_element(By.ID, \"twotabsearchtextbox\")\n",
    "search_box.send_keys(product_name)\n",
    "search_box.send_keys(Keys.RETURN)\n",
    "\n",
    "\n",
    "time.sleep(3)\n",
    "\n",
    "# Extract product det\n",
    "products = []\n",
    "try:\n",
    "   \n",
    "    product_containers = driver.find_elements(By.XPATH, '//div[@data-component-type=\"s-search-result\"]')\n",
    "\n",
    "    for container in product_containers:\n",
    "        # product name\n",
    "        try:\n",
    "            name = container.find_element(By.XPATH, './/h2/a/span').text\n",
    "        except:\n",
    "            name = '-'\n",
    "        \n",
    "        # product price\n",
    "        try:\n",
    "            price = container.find_element(By.XPATH, './/span[@class=\"a-price-whole\"]').text\n",
    "        except:\n",
    "            price = '-'\n",
    "\n",
    "        # product rating\n",
    "        try:\n",
    "            rating = container.find_element(By.XPATH, './/span[@class=\"a-icon-alt\"]').text\n",
    "        except:\n",
    "            rating = '-'\n",
    "\n",
    "        # Append product details to the list\n",
    "        products.append({\n",
    "            'Product Name': name,\n",
    "            'Price': price,\n",
    "            'Rating': rating\n",
    "        })\n",
    "finally:\n",
    "    driver.quit()\n",
    "\n",
    "# Convert to DataFrame \n",
    "df = pd.DataFrame(products)\n",
    "df.replace('', '-', inplace=True)  # Replace empty values with hyphens\n",
    "print(df)\n",
    "\n",
    "# save to CSV\n",
    "df.to_csv('amazon_products.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6c296a12-e3ed-4d63-baac-beee158d43fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter the product to search:  television\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping page 1...\n",
      "Scraping page 2...\n",
      "Scraping page 3...\n",
      "   Brand Name                                       Product Name     Price  \\\n",
      "0           -  Xiaomi 125 cm (50 inches) X Series 4K LED Smar...    33,999   \n",
      "1           -  Xiaomi 138 cm (55 inches) X Pro QLED Series Sm...    49,999   \n",
      "2           -  Redmi 80 cm (32 inches) F Series HD Ready Smar...    10,999   \n",
      "3           -  VW 80 cm (32 inches) Frameless Series HD Ready...     7,499   \n",
      "4           -  Kodak 80 cm (32 inches) Special Edition Series...     7,999   \n",
      "..        ...                                                ...       ...   \n",
      "61          -  LG 139 cm (55 inches) 4K Ultra HD Smart OLED T...  1,04,990   \n",
      "62          -  TOSHIBA 189 cm (75 inches) C350NP Series 4K Ul...    82,999   \n",
      "63          -  Sony Bravia 164 cm (65 inches) 4K Ultra HD Sma...    77,990   \n",
      "64          -  MI 108 cm (43 inches) A Series Full HD Smart G...    21,999   \n",
      "65          -  Xiaomi 108 cm (43 inches) X Series 4K LED Smar...    26,999   \n",
      "\n",
      "   Return/Exchange Expected Delivery Availability  \\\n",
      "0                -                 -            -   \n",
      "1                -                 -            -   \n",
      "2                -                 -            -   \n",
      "3                -                 -            -   \n",
      "4                -                 -            -   \n",
      "..             ...               ...          ...   \n",
      "61               -                 -            -   \n",
      "62               -                 -            -   \n",
      "63               -                 -            -   \n",
      "64               -                 -            -   \n",
      "65               -                 -            -   \n",
      "\n",
      "                                          Product URL  \n",
      "0   https://www.amazon.in/sspa/click?ie=UTF8&spc=M...  \n",
      "1   https://www.amazon.in/sspa/click?ie=UTF8&spc=M...  \n",
      "2   https://www.amazon.in/Redmi-inches-Ready-Smart...  \n",
      "3   https://www.amazon.in/Visio-World-inches-VW32S...  \n",
      "4   https://www.amazon.in/KODAK-inches-Special-Rea...  \n",
      "..                                                ...  \n",
      "61  https://www.amazon.in/LG-Inches-Ultra-Smart-OL...  \n",
      "62  https://www.amazon.in/TOSHIBA-inches-C350NP-Re...  \n",
      "63  https://www.amazon.in/Sony-Bravia-inches-Googl...  \n",
      "64  https://www.amazon.in/sspa/click?ie=UTF8&spc=M...  \n",
      "65  https://www.amazon.in/sspa/click?ie=UTF8&spc=M...  \n",
      "\n",
      "[66 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "'''Qn2\n",
    "\n",
    "In the above question, now scrape the following details of each product listed in first 3 pages of your search \n",
    "results and save it in a data frame and csv. In case if any product has less than 3 pages in search results then \n",
    "scrape all the products available under that product name. Details to be scraped are: \"Brand \n",
    "Name\", \"Name of the Product\", \"Price\", \"Return/Exchange\", \"Expected Delivery\", \"Availability\" and \n",
    "“Product URL”. In case, if any of the details are missing for any of the product then replace it by “-“.\n",
    "'''\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "path_chromedriver = r'C:\\chromedriver-win64\\chromedriver.exe'  # path to chromedriver executable\n",
    "service = Service(path_chromedriver)\n",
    "driver = webdriver.Chrome(service=service)\n",
    "\n",
    "\n",
    "\n",
    "# user input for product to search\n",
    "product_name = input(\"Enter the product to search: \")\n",
    "\n",
    "# Open Amazon.in \n",
    "driver.get('https://www.amazon.in')\n",
    "\n",
    "# Wait for the page to load completely\n",
    "time.sleep(3)\n",
    "\n",
    "# Land enter the product name\n",
    "search_box = driver.find_element(By.ID, \"twotabsearchtextbox\")\n",
    "search_box.send_keys(product_name)\n",
    "search_box.send_keys(Keys.RETURN)\n",
    "\n",
    "# Wait for the search results to load\n",
    "time.sleep(3)\n",
    "\n",
    "# Function to scrape details from the current page\n",
    "def scrape_page():\n",
    "    products = []\n",
    "    \n",
    "    \n",
    "    product_containers = driver.find_elements(By.XPATH, '//div[@data-component-type=\"s-search-result\"]')\n",
    "\n",
    "    for container in product_containers:\n",
    "        # Extract product name\n",
    "        try:\n",
    "            product_name = container.find_element(By.XPATH, './/h2/a/span').text\n",
    "        except:\n",
    "            product_name = '-'\n",
    "        \n",
    "        # Extract product URL\n",
    "        try:\n",
    "            product_url = container.find_element(By.XPATH, './/h2/a').get_attribute('href')\n",
    "        except:\n",
    "            product_url = '-'\n",
    "\n",
    "        # Extract brand name (it may sometimes be part of product name)\n",
    "        try:\n",
    "            brand_name = container.find_element(By.XPATH, './/h5/span').text\n",
    "        except:\n",
    "            brand_name = '-'\n",
    "\n",
    "        # Extract product price\n",
    "        try:\n",
    "            price = container.find_element(By.XPATH, './/span[@class=\"a-price-whole\"]').text\n",
    "        except:\n",
    "            price = '-'\n",
    "\n",
    "        # return/exchange policy \n",
    "        try:\n",
    "            return_exchange = container.find_element(By.XPATH, './/span[contains(text(),\"Return\")]').text\n",
    "        except:\n",
    "            return_exchange = '-'\n",
    "\n",
    "        # expected delivery date\n",
    "        try:\n",
    "            expected_delivery = container.find_element(By.XPATH, './/span[contains(text(),\"Get it by\")]').text\n",
    "        except:\n",
    "            expected_delivery = '-'\n",
    "\n",
    "        # availability status \n",
    "        try:\n",
    "            availability = container.find_element(By.XPATH, './/span[contains(text(),\"In stock\")]').text\n",
    "        except:\n",
    "            availability = '-'\n",
    "\n",
    "        # Append product details to the list\n",
    "        products.append({\n",
    "            'Brand Name': brand_name,\n",
    "            'Product Name': product_name,\n",
    "            'Price': price,\n",
    "            'Return/Exchange': return_exchange,\n",
    "            'Expected Delivery': expected_delivery,\n",
    "            'Availability': availability,\n",
    "            'Product URL': product_url\n",
    "        })\n",
    "    \n",
    "    return products\n",
    "\n",
    "# Initialize list \n",
    "all_products = []\n",
    "\n",
    "# Scrape products from the first 3 pages \n",
    "for page in range(1, 4):\n",
    "    print(f\"Scraping page {page}...\")\n",
    "    \n",
    "    \n",
    "    all_products.extend(scrape_page())\n",
    "    \n",
    "    \n",
    "    try:\n",
    "        next_button = driver.find_element(By.XPATH, '//a[contains(@class, \"s-pagination-next\")]')\n",
    "        next_button.click()\n",
    "        time.sleep(3) \n",
    "    except:\n",
    "        print(\"No more pages found.\")\n",
    "        break\n",
    "\n",
    "\n",
    "driver.quit()\n",
    "\n",
    "# Convert the product data into a pandas DataFrame\n",
    "df = pd.DataFrame(all_products)\n",
    "df.replace('', '-', inplace=True)  # Replace any empty values with hyphens\n",
    "\n",
    "# Save the data to CSV file\n",
    "df.to_csv('amazon_products.csv', index=False)\n",
    "\n",
    "\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "293e3849-1f84-441a-9f6d-9c8287c67d07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching for fruits...\n",
      "Searching for cars...\n",
      "Searching for Machine Learning...\n",
      "Searching for Guitar...\n",
      "Searching for Cakes...\n",
      "Image scraping and downloading completed!\n"
     ]
    }
   ],
   "source": [
    "'''Qn3\n",
    "Write a python program to access the search bar and search button on images.google.com and scrape 10 \n",
    "images each for keywords ‘fruits’, ‘cars’ and ‘Machine Learning’, ‘Guitar’, ‘Cakes’. \n",
    "'''\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import time\n",
    "import requests\n",
    "import os\n",
    "\n",
    "\n",
    "path_chromedriver = r'C:\\chromedriver-win64\\chromedriver.exe'  # path to chromedriver executable\n",
    "service = Service(path_chromedriver)\n",
    "driver = webdriver.Chrome(service=service)\n",
    "\n",
    "# Keywords to search for\n",
    "keywords = ['fruits', 'cars', 'Machine Learning', 'Guitar', 'Cakes']\n",
    "\n",
    "# scrape images for a specific keyword\n",
    "def scrape_images(keyword, num_images=10):\n",
    "    print(f\"Searching for {keyword}...\")\n",
    "    \n",
    "    \n",
    "    driver.get('https://images.google.com')\n",
    "    time.sleep(2)\n",
    "    \n",
    "    # search bar and enter the keyword\n",
    "    search_box = driver.find_element(By.NAME, 'q')\n",
    "    search_box.send_keys(keyword)\n",
    "    search_box.send_keys(Keys.RETURN)\n",
    "    \n",
    "  \n",
    "    time.sleep(2)\n",
    "\n",
    "   \n",
    "    for _ in range(3):\n",
    "        driver.execute_script(\"window.scrollBy(0,document.body.scrollHeight)\")\n",
    "        time.sleep(2)\n",
    "\n",
    "    # image URLs\n",
    "    image_urls = []\n",
    "    image_elements = driver.find_elements(By.XPATH, '//img[@class=\"rg_i Q4LuWd\"]')\n",
    "\n",
    "    for image in image_elements[:num_images]:\n",
    "        try:\n",
    "            \n",
    "            image.click()\n",
    "            time.sleep(2)\n",
    "            large_image = driver.find_element(By.XPATH, '//img[@class=\"n3VNCb\"]')\n",
    "            image_url = large_image.get_attribute('src')\n",
    "            if 'http' in image_url:  # Only add valid image URLs\n",
    "                image_urls.append(image_url)\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "    return image_urls\n",
    "\n",
    "# download images from URLs\n",
    "def download_images(image_urls, keyword):\n",
    "    # Create a directory for the keyword\n",
    "    if not os.path.exists(keyword):\n",
    "        os.makedirs(keyword)\n",
    "    \n",
    "    # Download and save images\n",
    "    for i, url in enumerate(image_urls):\n",
    "        try:\n",
    "            response = requests.get(url)\n",
    "            if response.status_code == 200:\n",
    "                with open(f\"{keyword}/{keyword}_{i+1}.jpg\", 'wb') as file:\n",
    "                    file.write(response.content)\n",
    "            else:\n",
    "                print(f\"Failed to download image {i+1} from {url}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error downloading image {i+1}: {e}\")\n",
    "\n",
    "# Scrape and download images \n",
    "for keyword in keywords:\n",
    "    image_urls = scrape_images(keyword, num_images=10)\n",
    "    download_images(image_urls, keyword)\n",
    "\n",
    "\n",
    "driver.quit()\n",
    "\n",
    "print(\"Image scraping and downloading completed!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0da2d586-8580-4dde-b0ff-733682e32501",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Qn4:\n",
    "Write a python program to search for a smartphone(e.g.: Oneplus Nord, pixel 4A, etc.) on www.flipkart.com\n",
    "and scrape following details for all the search results displayed on 1st page. Details to be scraped: “Brand \n",
    "Name”, “Smartphone name”, “Colour”, “RAM”, “Storage(ROM)”, “Primary Camera”, \n",
    "“Secondary Camera”, “Display Size”, “Battery Capacity”, “Price”, “Product URL”. Incase if any of the \n",
    "details is missing then replace it by “- “. Save your results in a dataframe and CSV. \n",
    "'''\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "path_chromedriver = r'C:\\chromedriver-win64\\chromedriver.exe'  # path to chromedriver executable\n",
    "service = Service(path_chromedriver)\n",
    "driver = webdriver.Chrome(service=service)\n",
    "\n",
    "# Get the smartphone to search from user input\n",
    "smartphone_name = input(\"Enter the smartphone name to search: \")\n",
    "\n",
    "\n",
    "driver.get('https://www.flipkart.com')\n",
    "time.sleep(3)\n",
    "\n",
    "# Close the login popup if appears\n",
    "try:\n",
    "    close_popup = driver.find_element(By.XPATH, '//button[contains(text(),\"✕\")]')\n",
    "    close_popup.click()\n",
    "except:\n",
    "    pass\n",
    "\n",
    "# enter the smartphone name\n",
    "search_box = driver.find_element(By.NAME, 'q')\n",
    "search_box.send_keys(smartphone_name)\n",
    "search_box.send_keys(Keys.RETURN)\n",
    "\n",
    "\n",
    "time.sleep(3)\n",
    "\n",
    "# Function to scrape details search results\n",
    "def scrape_smartphones():\n",
    "    smartphones = []\n",
    "    \n",
    "  \n",
    "    product_containers = driver.find_elements(By.XPATH, '//div[@class=\"_1AtVbE\"]//div[@class=\"_13oc-S\"]')\n",
    "\n",
    "    for container in product_containers:\n",
    "        # Extract brand and smartphone name\n",
    "        try:\n",
    "            smartphone_name = container.find_element(By.XPATH, './/div[@class=\"_4rR01T\"]').text\n",
    "            brand_name = smartphone_name.split()[0]  # First word is usually the brand\n",
    "        except:\n",
    "            smartphone_name = '-'\n",
    "            brand_name = '-'\n",
    "\n",
    "        # Extract product URL\n",
    "        try:\n",
    "            product_url = container.find_element(By.XPATH, './/a').get_attribute('href')\n",
    "        except:\n",
    "            product_url = '-'\n",
    "\n",
    "        # Extract price\n",
    "        try:\n",
    "            price = container.find_element(By.XPATH, './/div[@class=\"_30jeq3 _1_WHN1\"]').text\n",
    "        except:\n",
    "            price = '-'\n",
    "\n",
    "        # Extract other specifications\n",
    "        try:\n",
    "            specs = container.find_element(By.XPATH, './/ul[@class=\"_1xgFaf\"]').text.split('\\n')\n",
    "        except:\n",
    "            specs = []\n",
    "\n",
    "        \n",
    "        color, ram, rom, primary_camera, secondary_camera, display_size, battery_capacity = '-', '-', '-', '-', '-', '-', '-'\n",
    "\n",
    "        \n",
    "        for spec in specs:\n",
    "            if 'RAM' in spec and 'ROM' in spec:\n",
    "                ram = spec.split('|')[0].strip()\n",
    "                rom = spec.split('|')[1].strip()\n",
    "            elif 'Display' in spec:\n",
    "                display_size = spec\n",
    "            elif 'Battery' in spec:\n",
    "                battery_capacity = spec\n",
    "            elif 'Camera' in spec and 'Primary' in spec:\n",
    "                primary_camera = spec\n",
    "            elif 'Camera' in spec and 'Secondary' in spec:\n",
    "                secondary_camera = spec\n",
    "            elif 'Color' in spec:\n",
    "                color = spec\n",
    "\n",
    "        # Append the smartphone details to the list\n",
    "        smartphones.append({\n",
    "            'Brand Name': brand_name,\n",
    "            'Smartphone Name': smartphone_name,\n",
    "            'Colour': color,\n",
    "            'RAM': ram,\n",
    "            'Storage (ROM)': rom,\n",
    "            'Primary Camera': primary_camera,\n",
    "            'Secondary Camera': secondary_camera,\n",
    "            'Display Size': display_size,\n",
    "            'Battery Capacity': battery_capacity,\n",
    "            'Price': price,\n",
    "            'Product URL': product_url\n",
    "        })\n",
    "    \n",
    "    return smartphones\n",
    "\n",
    "# Scrape the smartphone data\n",
    "smartphone_data = scrape_smartphones()\n",
    "\n",
    "\n",
    "driver.quit()\n",
    "\n",
    "# Convert the data into a pandas DataFrame\n",
    "df = pd.DataFrame(smartphone_data)\n",
    "df.replace('', '-', inplace=True)  # Replace any empty values with hyphens\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "df.to_csv('flipkart_smartphones.csv', index=False)\n",
    "\n",
    "\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fed8e748-e04e-4923-99b2-595db3f51562",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter the city name:  CHENNAI\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coordinates of CHENNAI:\n",
      "Latitude: 13.0473168\n",
      "Longitude: 79.8793111\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Qn5:\n",
    "\n",
    "Write a program to scrap geospatial coordinates (latitude, longitude) of a city searched on google maps.\n",
    "\n",
    "'''\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import time\n",
    "\n",
    "# Set up the Chrome webdriver service\n",
    "path_chromedriver = r'C:\\chromedriver-win64\\chromedriver.exe'  # path to chromedriver executable\n",
    "service = Service(path_chromedriver)\n",
    "driver = webdriver.Chrome(service=service)\n",
    "\n",
    "# Get the city name \n",
    "city_name = input(\"Enter the city name: \")\n",
    "\n",
    "# Open Google Maps\n",
    "driver.get('https://www.google.com/maps')\n",
    "time.sleep(3)  \n",
    "\n",
    "# Find the search bar and enter the city name\n",
    "search_box = driver.find_element(By.ID, \"searchboxinput\")\n",
    "search_box.send_keys(city_name)\n",
    "search_box.send_keys(Keys.RETURN)\n",
    "\n",
    "\n",
    "time.sleep(5)\n",
    "\n",
    "\n",
    "current_url = driver.current_url\n",
    "\n",
    "# Close browser\n",
    "driver.quit()\n",
    "\n",
    "# Extract latitude and longitude from the URL\n",
    "try:\n",
    "   \n",
    "    url_parts = current_url.split('@')[1].split(',')\n",
    "    latitude = url_parts[0]\n",
    "    longitude = url_parts[1]\n",
    "    \n",
    "    print(f\"Coordinates of {city_name}:\")\n",
    "    print(f\"Latitude: {latitude}\")\n",
    "    print(f\"Longitude: {longitude}\")\n",
    "except Exception as e:\n",
    "    print(f\"Could not extract coordinates: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f83be0-55f8-4241-a189-4445b63dfb7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Qn6:\n",
    "Write a program to scrap all the available details of best gaming laptops from digit.in. \n",
    "'''\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "path_chromedriver = r'C:\\chromedriver-win64\\chromedriver.exe'  # path to chromedriver executable\n",
    "service = Service(path_chromedriver)\n",
    "driver = webdriver.Chrome(service=service)\n",
    "\n",
    "# URL of the best gaming laptops page on digit.in\n",
    "url = \"https://www.digit.in/top-products/best-gaming-laptops-40.html\"\n",
    "\n",
    "\n",
    "driver.get(url)\n",
    "\n",
    "\n",
    "time.sleep(5)\n",
    "\n",
    "# Initialize an empty list to store the laptop details\n",
    "laptop_data = []\n",
    "\n",
    "# Find all laptop sections on the page\n",
    "laptops = driver.find_elements(By.CSS_SELECTOR, \"div.TopNumbeHeading\")\n",
    "\n",
    "for laptop in laptops:\n",
    "    # Extract the laptop \n",
    "    try:\n",
    "        laptop_name = laptop.find_element(By.TAG_NAME, \"h2\").text.strip()\n",
    "    except:\n",
    "        laptop_name = '-'\n",
    "    \n",
    "    # Extract price\n",
    "    try:\n",
    "        price = laptop.find_element(By.CLASS_NAME, \"price\").text.strip()\n",
    "    except:\n",
    "        price = '-'\n",
    "\n",
    "    # Extract specifications\n",
    "    try:\n",
    "        specs = laptop.find_element(By.CLASS_NAME, \"Section-center\").text.strip().split('\\n')\n",
    "        specs = [spec.strip() for spec in specs if spec.strip()]\n",
    "    except:\n",
    "        specs = []\n",
    "\n",
    "    # Create dictionary for laptop details\n",
    "    laptop_details = {\n",
    "        \"Laptop Name\": laptop_name,\n",
    "        \"Price\": price,\n",
    "        \"Specifications\": \"; \".join(specs) if specs else '-'\n",
    "    }\n",
    "\n",
    "    # Append laptop details to the list\n",
    "    laptop_data.append(laptop_details)\n",
    "\n",
    "\n",
    "driver.quit()\n",
    "\n",
    "# Convert list of laptop data into a pandas DataFrame\n",
    "df = pd.DataFrame(laptop_data)\n",
    "\n",
    "# Display DataFrame\n",
    "print(df)\n",
    "\n",
    "# Save DataFrame to a CSV file\n",
    "df.to_csv(\"best_gaming_laptops_digit.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88335242-4ac9-4899-a587-d470b6ed6e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Qn7:\n",
    "Write a python program to scrape the details for all billionaires from www.forbes.com. Details to be scrapped: \n",
    "“Rank”, “Name”, “Net worth”, “Age”, “Citizenship”, “Source”, “Industry”. \n",
    "'''\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "path_chromedriver = r'C:\\chromedriver-win64\\chromedriver.exe'  # path to chromedriver executable\n",
    "service = Service(path_chromedriver)\n",
    "driver = webdriver.Chrome(service=service)\n",
    "\n",
    "# URL of Forbes Billionaires list\n",
    "url = \"https://www.forbes.com/billionaires/\"\n",
    "\n",
    "\n",
    "driver.get(url)\n",
    "\n",
    "\n",
    "time.sleep(5)\n",
    "\n",
    "# Initialize an empty list \n",
    "billionaires_data = []\n",
    "\n",
    "\n",
    "driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "time.sleep(5)\n",
    "\n",
    "# Loop through all billionaire entries\n",
    "billionaires = driver.find_elements(By.CSS_SELECTOR, \"div.personName\")\n",
    "\n",
    "for billionaire in billionaires:\n",
    "    # Extract rank\n",
    "    try:\n",
    "        rank = billionaire.find_element(By.XPATH, \".//div[@class='rank']\").text\n",
    "    except:\n",
    "        rank = '-'\n",
    "    \n",
    "    # Extract name\n",
    "    try:\n",
    "        name = billionaire.find_element(By.CSS_SELECTOR, \".personName\").text\n",
    "    except:\n",
    "        name = '-'\n",
    "    \n",
    "    # Extract net worth\n",
    "    try:\n",
    "        net_worth = billionaire.find_element(By.CSS_SELECTOR, \".netWorth\").text\n",
    "    except:\n",
    "        net_worth = '-'\n",
    "    \n",
    "    # Extract age\n",
    "    try:\n",
    "        age = billionaire.find_element(By.CSS_SELECTOR, \".age\").text\n",
    "    except:\n",
    "        age = '-'\n",
    "    \n",
    "    # Extract citizenship\n",
    "    try:\n",
    "        citizenship = billionaire.find_element(By.CSS_SELECTOR, \".countryOfCitizenship\").text\n",
    "    except:\n",
    "        citizenship = '-'\n",
    "    \n",
    "    # Extract source of wealth\n",
    "    try:\n",
    "        source = billionaire.find_element(By.CSS_SELECTOR, \".source\").text\n",
    "    except:\n",
    "        source = '-'\n",
    "    \n",
    "    # Extract industry\n",
    "    try:\n",
    "        industry = billionaire.find_element(By.CSS_SELECTOR, \".category\").text\n",
    "    except:\n",
    "        industry = '-'\n",
    "    \n",
    "    # Append data to the list\n",
    "    billionaires_data.append({\n",
    "        'Rank': rank,\n",
    "        'Name': name,\n",
    "        'Net Worth': net_worth,\n",
    "        'Age': age,\n",
    "        'Citizenship': citizenship,\n",
    "        'Source': source,\n",
    "        'Industry': industry\n",
    "    })\n",
    "\n",
    "\n",
    "driver.quit()\n",
    "\n",
    "# Convert list of data into a pandas DataFrame\n",
    "df = pd.DataFrame(billionaires_data)\n",
    "\n",
    "# Display the DataFrame\n",
    "print(df)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "df.to_csv(\"forbes_billionaires.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1974374-6cc0-4c5a-9906-b46d5d09996f",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Qn8:\n",
    "Write a program to extract at least 500 Comments, Comment upvote and time when comment was posted \n",
    "from any YouTube Video. from selenium import webdriver\n",
    "'''\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "path_chromedriver = r'C:\\chromedriver-win64\\chromedriver.exe'  # path to chromedriver executable\n",
    "service = Service(path_chromedriver)\n",
    "driver = webdriver.Chrome(service=service)\n",
    "\n",
    "# URL of the YouTube video \n",
    "youtube_video_url = \"https://www.youtube.com/watch?v=GwIo3gDZCVQ\"\n",
    "\n",
    "# Open the YouTube page\n",
    "driver.get(youtube_video_url)\n",
    "\n",
    "\n",
    "time.sleep(5)\n",
    "\n",
    "# Scroll to the comments section\n",
    "driver.execute_script(\"window.scrollTo(0, 800);\")\n",
    "time.sleep(3)\n",
    "\n",
    "\n",
    "num_scrolls = 20  # the number of scrolls \n",
    "for _ in range(num_scrolls):\n",
    "    driver.execute_script(\"window.scrollTo(0, document.documentElement.scrollHeight);\")\n",
    "    time.sleep(3)  \n",
    "\n",
    "# Initialize lists to store data\n",
    "comments_data = []\n",
    "\n",
    "# Find all comment sections on the page\n",
    "comments = driver.find_elements(By.XPATH, '//*[@id=\"content-text\"]')\n",
    "upvotes = driver.find_elements(By.XPATH, '//*[@id=\"vote-count-middle\"]')\n",
    "timestamps = driver.find_elements(By.XPATH, '//*[@id=\"header-author\"]/yt-formatted-string/a')\n",
    "\n",
    "# Extract at least 500 comments\n",
    "for i in range(min(5, len(comments))):\n",
    " try:\n",
    "    comment_text = comments[i].text\n",
    "    upvote_count = upvotes[i].text if upvotes[i].text != '' else '0'  # Default to 0 if no upvotes are shown\n",
    "    timestamp = timestamps[i].text\n",
    " except:\n",
    "    break\n",
    "\n",
    "    # Append data to the list\n",
    "    comments_data.append({\n",
    "        'Comment': comment_text,\n",
    "        'Upvotes': upvote_count,\n",
    "        'Timestamp': timestamp\n",
    "\n",
    "    })\n",
    "\n",
    "\n",
    "driver.quit()\n",
    "\n",
    "# Convert list of data into a pandas DataFrame\n",
    "df = pd.DataFrame(comments_data)\n",
    "\n",
    "# Display the DataFrame\n",
    "print(df)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "df.to_csv(\"youtube_comments.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53d633af-e8a1-484b-9e1b-4e8afb290835",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Qn 9:\n",
    "Write a python program to scrape a data for all available Hostels from https://www.hostelworld.com/ in \n",
    "“London” location. You have to scrape hostel name, distance from city centre, ratings, total reviews, overall \n",
    "reviews, privates from price, dorms from price, facilities and property description. from selenium import webdriver\n",
    "'''\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "path_chromedriver = r'C:\\chromedriver-win64\\chromedriver.exe'  # path to chromedriver executable\n",
    "service = Service(path_chromedriver)\n",
    "driver = webdriver.Chrome(service=service)\n",
    "\n",
    "# URL of the hostel search page for London\n",
    "url = \"https://www.hostelworld.com/s?q=London&city=London&type=city&id=3&from=2022-12-14&guests=2\"\n",
    "\n",
    "# Open the hostelworld page \n",
    "driver.get(url)\n",
    "\n",
    "\n",
    "time.sleep(5)\n",
    "\n",
    "# Initialize an empty list \n",
    "hostel_data = []\n",
    "\n",
    "# Scroll and load more hostels \n",
    "for _ in range(5):  \n",
    "    driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "    time.sleep(3)\n",
    "\n",
    "# Find all the hostel sections on the page\n",
    "hostels = driver.find_elements(By.CLASS_NAME, 'property')\n",
    "\n",
    "# Loop through each hostel and extract the details\n",
    "for hostel in hostels:\n",
    "    # Extract the hostel name\n",
    "    try:\n",
    "        hostel_name = hostel.find_element(By.CLASS_NAME, 'title').text.strip()\n",
    "    except:\n",
    "        hostel_name = '-'\n",
    "\n",
    "    # Extract the distance from city center\n",
    "    try:\n",
    "        distance = hostel.find_element(By.CLASS_NAME, 'distance').text.strip()\n",
    "    except:\n",
    "        distance = '-'\n",
    "\n",
    "    # Extract the rating\n",
    "    try:\n",
    "        rating = hostel.find_element(By.CLASS_NAME, 'score').text.strip()\n",
    "    except:\n",
    "        rating = '-'\n",
    "\n",
    "    # Extract the total reviews\n",
    "    try:\n",
    "        total_reviews = hostel.find_element(By.CLASS_NAME, 'reviews').text.strip()\n",
    "    except:\n",
    "        total_reviews = '-'\n",
    "\n",
    "    # Extract the overall reviews \n",
    "    try:\n",
    "        overall_reviews = hostel.find_element(By.CLASS_NAME, 'keyword').text.strip()\n",
    "    except:\n",
    "        overall_reviews = '-'\n",
    "\n",
    "    # Extract the price \n",
    "    try:\n",
    "        privates_from_price = hostel.find_element(By.CLASS_NAME, 'price-privates').text.strip().replace('\\n', ' ')\n",
    "    except:\n",
    "        privates_from_price = '-'\n",
    "\n",
    "    # Extract the price for dorms\n",
    "    try:\n",
    "        dorms_from_price = hostel.find_element(By.CLASS_NAME, 'price-dorms').text.strip().replace('\\n', ' ')\n",
    "    except:\n",
    "        dorms_from_price = '-'\n",
    "\n",
    "    # Extract the facilities\n",
    "    try:\n",
    "        facilities = hostel.find_element(By.CLASS_NAME, 'facilities').text.strip().replace('\\n', ', ')\n",
    "    except:\n",
    "        facilities = '-'\n",
    "\n",
    "    # Extract the property description\n",
    "    try:\n",
    "        property_description = hostel.find_element(By.CLASS_NAME, 'description').text.strip()\n",
    "    except:\n",
    "        property_description = '-'\n",
    "\n",
    "    # Append the hostel details to the list\n",
    "    hostel_data.append({\n",
    "        'Hostel Name': hostel_name,\n",
    "        'Distance from City Centre': distance,\n",
    "        'Rating': rating,\n",
    "        'Total Reviews': total_reviews,\n",
    "        'Overall Reviews': overall_reviews,\n",
    "        'Privates From Price': privates_from_price,\n",
    "        'Dorms From Price': dorms_from_price,\n",
    "        'Facilities': facilities,\n",
    "        'Property Description': property_description\n",
    "    })\n",
    "\n",
    "\n",
    "driver.quit()\n",
    "\n",
    "# Convert the list of hostel data into a pandas DataFrame\n",
    "df = pd.DataFrame(hostel_data)\n",
    "\n",
    "# Display the DataFrame\n",
    "print(df)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "df.to_csv(\"hostels_in_london.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33decbc0-ef7f-42dd-b826-3640794f585b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
